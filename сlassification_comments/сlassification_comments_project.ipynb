{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Часть 1. Загрузка и подготовка данных:\n",
    "* [1. Подключение необходимых библиотек и импортирование функций.](#11.1-bullet)\n",
    "* [2. Загрузка данных.](#11.2-bullet)\n",
    "* [3. Подготовка данных.](#11.3-bullet)\n",
    "\n",
    "##### Часть 2. Обучение моделей:\n",
    "* [4. Обучение модели \"Логистическая регрессия\".](#11.4-bullet)\n",
    "* [5. Обучение модели \"Случайный лес\".](#11.5-bullet)\n",
    "\n",
    "##### Часть 3. Выводы:\n",
    "* [6. Выводы.](#11.6-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Загрузка и подготовка данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11.1-bullet'></a> \n",
    "### 1. Подключение необходимых библиотек и импортирование функций. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "RANDOM_STATE = 123456\n",
    "LOW_SEARCH_DEPTH = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11.2-bullet'></a> \n",
    "### 2. Загрузка данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('../datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем общую информацию о данных в таблице *data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеем в базе 2 колонки. Текст и маркер токсичности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11.3-bullet'></a> \n",
    "### 3. Подготовка данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пара вспомогательных классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ab_ProgressBar():\n",
    "    \n",
    "    def __init__(self, max=0):\n",
    "        self.max_count = max\n",
    "        self.spinner_state = 0\n",
    "        self.progress = 0\n",
    "        self.start_time = time.perf_counter()\n",
    "        self.progress_step = 100 / self.max_count\n",
    "        self.draw()\n",
    "    \n",
    "    def get_diff_time(self, t):\n",
    "        return int(t // 3600), int((t // 60) % 60), int(t % 60)\n",
    "    \n",
    "    def get_time_string(self):\n",
    "        return '{0[0]:02}:{0[1]:02}:{0[2]:02}'.format(self.get_diff_time(time.perf_counter() - self.start_time))\n",
    "    \n",
    "    def get_left_time_string(self):\n",
    "        cur_time = time.perf_counter() - self.start_time\n",
    "        try:\n",
    "            return '{0[0]:02}:{0[1]:02}:{0[2]:02}'.format(self.get_diff_time(max(0, cur_time * (100 - self.progress) / self.progress)))\n",
    "        except:\n",
    "            return ' - '\n",
    "            \n",
    "    def get_fill_progress(self):\n",
    "        count = int(self.progress / 2)\n",
    "        return '.' * count + ' ' * int(50 - count)\n",
    "    \n",
    "    def draw(self):\n",
    "        print(f'[{self.progress:.1f}%][time: {self.get_time_string()}][{self.get_fill_progress()}][time left: {self.get_left_time_string()}]', end='\\r')\n",
    " \n",
    "    def increment(self, count=1):\n",
    "        self.draw()\n",
    "        self.progress += self.progress_step * count\n",
    "    \n",
    "    def stop(self):\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSplitter():\n",
    "    \n",
    "    def __init__(self, random_state=RANDOM_STATE):\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def split_target(self, df, target_column, need_drop_target):\n",
    "        result = {'X': df, 'y': df[target_column]}\n",
    "        if need_drop_target:\n",
    "            result['X'] = result['X'].drop([target_column], axis=1)\n",
    "        return result\n",
    "    \n",
    "    def split(self, df, target_column='toxic', \n",
    "              part=None, test_size=0.2, valid_size=0.2,\n",
    "              shuffle=True, need_drop_target=True, train_with_valid=False):\n",
    "        train_test = train_test_split(df, test_size=test_size, \n",
    "                                      shuffle=shuffle, random_state=self.random_state)\n",
    "        train_valid = train_test_split(train_test[0], test_size=valid_size, \n",
    "                                       shuffle=shuffle, random_state=self.random_state)\n",
    "        split_data = {}\n",
    "        if train_with_valid:\n",
    "            split_data['train'] = self.split_target(train_test[0], target_column, need_drop_target)\n",
    "        else:\n",
    "            split_data['train'] = self.split_target(train_valid[0], target_column, need_drop_target)\n",
    "        \n",
    "        split_data['test'] = self.split_target(train_test[1], target_column, need_drop_target)\n",
    "        split_data['valid'] = self.split_target(train_valid[1], target_column, need_drop_target)\n",
    "        try:\n",
    "            self.X = split_data[part]['X']\n",
    "            self.y = split_data[part]['y']\n",
    "        except:\n",
    "            self.X = {'train': split_data['train']['X'], 'test': split_data['test']['X'], 'valid': split_data['valid']['X']}\n",
    "            self.y = {'train': split_data['train']['y'], 'test': split_data['test']['y'], 'valid': split_data['valid']['y']}\n",
    "\n",
    "    def balance(self, factor=None, technique='Upsampling'):\n",
    "        X_zeros, X_ones = self.X[self.y == 0], self.X[self.y == 1]\n",
    "        y_zeros, y_ones = self.y[self.y == 0], self.y[self.y == 1]\n",
    "        if factor == None:\n",
    "            if X_zeros.shape[0] > X_ones.shape[0]:\n",
    "                factor = X_zeros.shape[0] // X_ones.shape[0]\n",
    "            else:    \n",
    "                factor = X_ones.shape[0] // X_zeros.shape[0]\n",
    "        if technique == 'Upsampling':\n",
    "            new_X = pd.concat([X_zeros] + [X_ones] * factor)\n",
    "            new_y = pd.concat([y_zeros] + [y_ones] * factor)\n",
    "        elif technique == 'Downsampling':\n",
    "            new_X = pd.concat([X_zeros.sample(frac=1/factor, random_state=self.random_state)] + [X_ones])\n",
    "            new_y = pd.concat([target_zeros.sample(frac=1/factor, random_state=self.random_state)] + [y_ones])\n",
    "        \n",
    "        self.X, self.y = shuffle(new_X, new_y, random_state=self.random_state)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для подготовки тескста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем текст и очистим, оставив только кириллические символы и пробелы. Создадим новый столбец *lemm_text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text, progress_bar, m):\n",
    "    lemm_list = m.lemmatize(text)\n",
    "    lemm_text = ' '.join(re.sub(r\"[^a-zA-Z' ]\", ' ', ''.join(lemm_list)).split())\n",
    "    progress_bar.increment()\n",
    "    return lemm_text        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('../datasets/toxic_comments_lemm.csv')\n",
    "except:\n",
    "    m = Mystem()\n",
    "    progress_bar = ab_ProgressBar(data.shape[0])\n",
    "    data['lemm_text'] = data.text.apply(lemmatize, progress_bar=progress_bar, m=m)\n",
    "    progress_bar.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww He matches this background colour I'm se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I'm really not trying to edit war It's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can't make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  Explanation Why the edits made under my userna...  \n",
       "1  D'aww He matches this background colour I'm se...  \n",
       "2  Hey man I'm really not trying to edit war It's...  \n",
       "3  More I can't make any real suggestions on impr...  \n",
       "4  You sir are my hero Any chance you remember wh...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Обучение моделей. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим функцию для создания мешка слов без стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(df, count_tf_idf, stopwords, need_fit=False):\n",
    "    corpus = df.lemm_text.values.astype('U')\n",
    "    if need_fit:\n",
    "        tf_idf = count_tf_idf.fit_transform(corpus)\n",
    "    else:\n",
    "        tf_idf = count_tf_idf.transform(corpus)\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11.4-bullet'></a> \n",
    "### 4. Обучение модели \"Логистическая регрессия\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Andrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score на тестовой \"Логистическая регрессия\" 0.7579151112954515\n"
     ]
    }
   ],
   "source": [
    "split_data = DataSplitter()\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "split_data.split(data, part='train', train_with_valid=True)\n",
    "split_data.balance()\n",
    "model.fit(get_tf_idf(split_data.X, count_tf_idf, stopwords, need_fit=True), split_data.y)\n",
    "split_data.split(data, part='test')\n",
    "predicted = model.predict(get_tf_idf(split_data.X, count_tf_idf, stopwords))\n",
    "print('f1 score на тестовой \"Логистическая регрессия\"', f1_score(split_data.y, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11.5-bullet'></a> \n",
    "### 5. Обучение модели \"Случайный лес\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83.3%][time: 00:02:29][.........................................         ][time left: 00:00:29]\n",
      "Лучшие параметры: {'f1_score': 0.6459028550241009, 'n_estimators': 100, 'max_depth': 30}\n",
      "f1 score на тестовой \"Случайный лес\" 0.6657326982347997\n"
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    'f1_score': 0,\n",
    "    'n_estimators': 0,\n",
    "    'max_depth': 0,\n",
    "}\n",
    "split_data.split(data, part='train')\n",
    "split_data.balance()\n",
    "td_idf_train = get_tf_idf(split_data.X, count_tf_idf, stopwords, need_fit=True)\n",
    "y_train = split_data.y\n",
    "split_data.split(data, part='valid')\n",
    "td_idf_valid = get_tf_idf(split_data.X, count_tf_idf, stopwords)\n",
    "y_valid = split_data.y\n",
    "progress_bar = ab_ProgressBar((sum(range(20, 101, 20))) * (sum(range(10, 31, 10))))\n",
    "for n_estimators in range(20, 101, 20):\n",
    "    for max_depth in range(10, 31, 10):\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=RANDOM_STATE)\n",
    "        model.fit(td_idf_train, y_train)\n",
    "        split_data.split(data, part='test')\n",
    "        predicted = model.predict(td_idf_valid)\n",
    "        score = f1_score(y_valid, predicted)\n",
    "        if score > best_params['f1_score']:\n",
    "            best_params['f1_score'] = score\n",
    "            best_params['n_estimators'] = n_estimators\n",
    "            best_params['max_depth'] = max_depth\n",
    "        progress_bar.increment(n_estimators * max_depth)\n",
    "progress_bar.stop()\n",
    "print('Лучшие параметры:', best_params)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=best_params['n_estimators'], max_depth=best_params['max_depth'], random_state=RANDOM_STATE)\n",
    "split_data.split(data, part='train', train_with_valid=True)\n",
    "split_data.balance()\n",
    "model.fit(get_tf_idf(split_data.X, count_tf_idf, stopwords, need_fit=True), split_data.y)\n",
    "split_data.split(data, part='test')\n",
    "predicted = model.predict(get_tf_idf(split_data.X, count_tf_idf, stopwords))\n",
    "print('f1 score на тестовой \"Случайный лес\"', f1_score(split_data.y, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='11.6-bullet'></a> \n",
    "## Часть 3. Выводы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики **f1** на тестовой выборке у модели \"Логистическая регрессия\" получилось **0.758**, что удовлетворительно в рамках данной задачи.\n",
    "\n",
    "В свою очередь модель случайного леса дала гораздо меньшее значение метрики F1 = **0.666**, кроме того, подбор гиперпараметров сильно затягивает обучение данной модели с таким количеством признаков.\n",
    "\n",
    "Таким образом мы смогли обучить модель, которая не тестовой выборке показала удовлетворительный результат."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
